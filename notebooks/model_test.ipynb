{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import pytest\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from lama_cleaner.helper import load_img\n",
    "\n",
    "from lama_cleaner.model_manager import ModelManager\n",
    "from lama_cleaner.schema import Config, HDStrategy, LDMSampler, SDSampler\n",
    "\n",
    "#current_dir = Path(__file__).parent.absolute().resolve()\n",
    "#save_dir = current_dir / \"result\"\n",
    "save_dir = Path(\"result\")\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "\n",
    "print(f\"Saving results to: {save_dir}\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data(\n",
    "        fx: float = 1,\n",
    "        fy: float = 1.0,\n",
    "        img_p = \"\",\n",
    "        mask_p = \"\"\n",
    "):\n",
    "    img = cv2.imread(str(img_p))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    mask = cv2.imread(str(mask_p), cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, None, fx=fx, fy=fy, interpolation=cv2.INTER_AREA)\n",
    "    mask = cv2.resize(mask, None, fx=fx, fy=fy, interpolation=cv2.INTER_NEAREST)\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "def get_data_2(\n",
    "        fx: float = 1,\n",
    "        fy: float = 1.0,\n",
    "        img_p = \"\",\n",
    "        mask_p = \"\",\n",
    "#        img_p=current_dir / \"image.png\",\n",
    "#        mask_p=current_dir / \"mask.png\",\n",
    "):\n",
    "    print(f\"Reading image from: {img_p}\")\n",
    "    img = cv2.imread(str(img_p))\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "    \n",
    "    #mask = cv2.imread(str(mask_p), cv2.IMREAD_GRAYSCALE)\n",
    "    #mask, _ = load_img(mask.read(), gray=True)\n",
    "\n",
    "    f = open(mask_p, \"rb\")\n",
    "    mask, alpha_channel = load_img(f.read())\n",
    "    \n",
    "    \n",
    "    #mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    \n",
    "    img = cv2.resize(img, None, fx=fx, fy=fy, interpolation=cv2.INTER_AREA)\n",
    "    mask = cv2.resize(mask, None, fx=fx, fy=fy, interpolation=cv2.INTER_NEAREST)\n",
    "    return img, mask\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ef0f78d5424705"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "p2pSteps: 50\n",
    "p2pImageGuidanceScale: 1.5\n",
    "p2pGuidanceScale: 7.5\n",
    "controlnet_conditioning_scale: 0.4\n",
    "controlnet_method: control_v11p_sd15_canny\n",
    "'''\n",
    "\n",
    "\n",
    "def get_config(strategy, **kwargs):\n",
    "    '''\n",
    "        data = dict(\n",
    "            ldm_steps=1,\n",
    "            ldm_sampler=LDMSampler.plms,\n",
    "            hd_strategy=strategy,\n",
    "            hd_strategy_crop_margin=32,\n",
    "            hd_strategy_crop_trigger_size=200,\n",
    "            hd_strategy_resize_limit=200,\n",
    "        )\n",
    "    '''\n",
    "\n",
    "    data = dict(\n",
    "        ldm_steps=25,\n",
    "        ldm_sampler=LDMSampler.plms,\n",
    "        hd_strategy=strategy,\n",
    "        zits_wireframe=True,\n",
    "        hd_strategy_crop_margin=196,\n",
    "        hd_strategy_crop_trigger_size=800,\n",
    "        hd_strategy_resize_limit=2048,\n",
    "        #prompt=,\n",
    "        #negative_prompt=,\n",
    "        use_croper=False,\n",
    "        croper_x=144,\n",
    "        croper_y=11,\n",
    "        croper_height=512,\n",
    "        croper_width=512,\n",
    "        sd_scale=1,\n",
    "        sd_mask_blur=5,\n",
    "        sd_strength=0.75,\n",
    "        sd_steps=50,\n",
    "        sd_guidance_scale=7.5,\n",
    "        sd_sampler=\"uni_pc\",\n",
    "        sd_seed=-1,\n",
    "        sd_match_histograms=False,\n",
    "        cv2_flag=\"INPAINT_NS\",\n",
    "        cv2_radius=5,\n",
    "        paint_by_example_steps=50,\n",
    "        paint_by_example_guidance_scale=7.5,\n",
    "        paint_by_example_mask_blur=5,\n",
    "        paint_by_example_seed=-1,\n",
    "        paint_by_example_match_histograms=False,\n",
    "        #paint_by_example_example_image=,\n",
    "        p2p_steps=50,\n",
    "        p2p_image_guidance_scale=1.5,\n",
    "        p2p_guidance_scale=7.5,\n",
    "        controlnet_conditioning_scale=0.4,\n",
    "        controlnet_method=\"control_v11p_sd15_canny\",\n",
    "    )\n",
    "    \n",
    "    data.update(**kwargs)\n",
    "    return Config(**data)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "697ef426e48fa5ae"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff45365274746065"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_mask_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def print_grayscale_image_stats(image_path):\n",
    "    #image = cv2.imread(image_path)\n",
    "\n",
    "    image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, None, fx=fx, fy=fy, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    height, width = image.shape\n",
    "    print(f\"w: {width}, h: {height}\")\n",
    "    \n",
    "    print(f\"Image path: {image_path}\")\n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "    print(f\"Image dtype: {image.dtype}\")\n",
    "    print(f\"Image min: {image.min()}\")\n",
    "\n",
    "def print_color_image_stats(image_path):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    image = cv2.resize(image, None, fx=fx, fy=fy, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    height, width, channels = image.shape\n",
    "    print(f\"w: {width}, h: {height}, channels: {channels}\")\n",
    "\n",
    "    print(f\"Image path: {image_path}\")\n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "    print(f\"Image dtype: {image.dtype}\")\n",
    "    print(f\"Image min: {image.min()}\")\n",
    "    \n",
    "mask_path = \"../output/dog/0.png\"\n",
    "image_path = \"../images/dog.jpg\"\n",
    "#print_grayscale_image_stats(mask_path)\n",
    "print_color_image_stats(image_path)\n",
    "print(\"\")\n",
    "\n",
    "mask_path_2 = \"../images/women_fence_mask.png\"\n",
    "image_path_2 = \"../images/women_fence.png\"\n",
    "#print_grayscale_image_stats(mask_path_2)\n",
    "print_color_image_stats(image_path_2)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa9105fe5129d1f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "fx = 1\n",
    "fy = 1\n",
    "\n",
    "#img, mask = get_data(fx=fx, fy=fy, img_p=\"../images/dog.jpg\", mask_p=\"../output/dog/0.png\")\n",
    "img, mask = get_data(fx=fx, fy=fy, img_p=\"../images/women_fence.png\", mask_p=\"../output/women_fence/0.png\")\n",
    "\n",
    "\n",
    "print(f\"Input image shape: {img.shape}\")\n",
    "\n",
    "model = ModelManager(name=\"lama\", device=device)\n",
    "strategy = HDStrategy.CROP\n",
    "config = get_config(strategy)\n",
    "gt_name = f\"lama_{strategy[0].upper() + strategy[1:]}_fx_{fx}_result.png\"\n",
    "\n",
    "res = model(img, mask, config)\n",
    "output_path = str(save_dir / gt_name)\n",
    "cv2.imwrite(\n",
    "    output_path,\n",
    "    res,\n",
    "    [int(cv2.IMWRITE_JPEG_QUALITY), 100, int(cv2.IMWRITE_PNG_COMPRESSION), 0],\n",
    ")\n",
    "print(f\"Saved result to: {output_path}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec3582445a32bb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(output_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb5d3eb46ea6e838"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e0df40e6629cf0b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
